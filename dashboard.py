import streamlit as st
import pandas as pd
import os
import plotly.express as px
import plotly.graph_objects as go
from sklearn.linear_model import LinearRegression
import numpy as np
import datetime as dt
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

load_dotenv()

st.set_page_config(page_title="Amazon FBA Ultimate BI", layout="wide", page_icon="üì¶")

DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

def get_engine():
    return create_engine(
        DATABASE_URL,
        connect_args={"options": "-csearch_path=spapi,public"}
    )

translations = {
    "UA": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ –û–Ω–æ–≤–∏—Ç–∏ –¥–∞–Ω—ñ",
        "sidebar_title": "üîç –§—ñ–ª—å—Ç—Ä–∏",
        "date_label": "üìÖ –î–∞—Ç–∞:",
        "store_label": "üè™ –ú–∞–≥–∞–∑–∏–Ω:",
        "all_stores": "–í—Å—ñ",
        "total_sku": "–í—Å—å–æ–≥–æ SKU",
        "total_avail": "–®—Ç—É–∫ –Ω–∞ —Å–∫–ª–∞–¥—ñ",
        "total_value": "üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å —Å–∫–ª–∞–¥—É",
        "velocity_30": "–ü—Ä–æ–¥–∞–∂—ñ (30 –¥–Ω—ñ–≤)",
        "chart_value_treemap": "üí∞ –î–µ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ñ –≥—Ä–æ—à—ñ?",
        "chart_velocity": "üöÄ –®–≤–∏–¥–∫—ñ—Å—Ç—å vs –ó–∞–ª–∏—à–∫–∏",
        "chart_age": "‚è≥ –í—ñ–∫ —ñ–Ω–≤–µ–Ω—Ç–∞—Ä—é",
        "top_money_sku": "üèÜ –¢–æ–ø SKU –∑–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—é",
        "top_qty_sku": "üèÜ –¢–æ–ø SKU –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é",
        "avg_price": "–°–µ—Ä–µ–¥–Ω—è —Ü—ñ–Ω–∞",
        "ai_header": "üß† AI –ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–ª–∏—à–∫—ñ–≤",
        "ai_select": "–û–±–µ—Ä—ñ—Ç—å SKU:",
        "ai_days": "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É:",
        "ai_result_date": "üìÖ –î–∞—Ç–∞ Sold-out:",
        "ai_result_days": "–î–Ω—ñ–≤ –∑–∞–ª–∏—à–∏–ª–æ—Å—å:",
        "ai_ok": "‚úÖ –ó–∞–ø–∞—Å—ñ–≤ –≤–∏—Å—Ç–∞—á–∏—Ç—å",
        "ai_error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É",
        "footer_date": "üìÖ –î–∞–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω–æ:",
        "download_excel": "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel",
        "settlements_title": "üè¶ –§—ñ–Ω–∞–Ω—Å–æ–≤—ñ –≤–∏–ø–ª–∞—Ç–∏ (Settlements)",
        "net_payout": "–ß–∏—Å—Ç–∞ –≤–∏–ø–ª–∞—Ç–∞",
        "gross_sales": "–í–∞–ª–æ–≤—ñ –ø—Ä–æ–¥–∞–∂—ñ",
        "total_fees": "–í—Å—å–æ–≥–æ –∫–æ–º—ñ—Å—ñ–π",
        "total_refunds": "–ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –∫–æ—à—Ç—ñ–≤",
        "chart_payout_trend": "üìâ –î–∏–Ω–∞–º—ñ–∫–∞ –≤–∏–ø–ª–∞—Ç",
        "chart_fee_breakdown": "üí∏ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∏—Ç—Ä–∞—Ç",
        "currency_select": "üí± –í–∞–ª—é—Ç–∞:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "–°–µ—Å—ñ—ó",
        "st_page_views": "–ü–µ—Ä–µ–≥–ª—è–¥–∏",
        "st_units": "–ó–∞–º–æ–≤–ª–µ–Ω–æ —à—Ç—É–∫",
        "st_conversion": "–ö–æ–Ω–≤–µ—Ä—Å—ñ—è",
        "st_revenue": "–î–æ—Ö—ñ–¥",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê –í—ñ–¥–≥—É–∫–∏ –ø–æ–∫—É–ø—Ü—ñ–≤",
        "total_reviews": "–í—Å—å–æ–≥–æ –≤—ñ–¥–≥—É–∫—ñ–≤",
        "avg_review_rating": "–°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥",
        "verified_pct": "–í–µ—Ä–∏—Ñ—ñ–∫–æ–≤–∞–Ω—ñ (%)",
        "star_dist": "–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ –∑—ñ—Ä–∫–∞—Ö",
        "worst_asin": "–ü—Ä–æ–±–ª–µ–º–Ω—ñ ASIN (1-2‚òÖ)",
    },
    "EN": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ Refresh Data",
        "sidebar_title": "üîç Filters",
        "date_label": "üìÖ Date:",
        "store_label": "üè™ Store:",
        "all_stores": "All",
        "total_sku": "Total SKU",
        "total_avail": "Total Units",
        "total_value": "üí∞ Inventory Value",
        "velocity_30": "Sales (30 days)",
        "chart_value_treemap": "üí∞ Where is the money?",
        "chart_velocity": "üöÄ Velocity vs Stock",
        "chart_age": "‚è≥ Inventory Age",
        "top_money_sku": "üèÜ Top SKU by Value",
        "top_qty_sku": "üèÜ Top SKU by Quantity",
        "avg_price": "Avg Price",
        "ai_header": "üß† AI Inventory Forecast",
        "ai_select": "Select SKU:",
        "ai_days": "Forecast Days:",
        "ai_result_date": "üìÖ Sold-out Date:",
        "ai_result_days": "Days left:",
        "ai_ok": "‚úÖ Stock sufficient",
        "ai_error": "Not enough data",
        "footer_date": "üìÖ Last update:",
        "download_excel": "üì• Download Excel",
        "settlements_title": "üè¶ Financial Settlements (Payouts)",
        "net_payout": "Net Payout",
        "gross_sales": "Gross Sales",
        "total_fees": "Total Fees",
        "total_refunds": "Total Refunds",
        "chart_payout_trend": "üìâ Payout Trend",
        "chart_fee_breakdown": "üí∏ Fee Breakdown",
        "currency_select": "üí± Currency:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "Sessions",
        "st_page_views": "Page Views",
        "st_units": "Units Ordered",
        "st_conversion": "Conversion",
        "st_revenue": "Revenue",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê Customer Reviews",
        "total_reviews": "Total Reviews",
        "avg_review_rating": "Average Rating",
        "verified_pct": "Verified (%)",
        "star_dist": "Star Distribution",
        "worst_asin": "Problematic ASINs (1-2‚òÖ)",
    },
    "RU": {
        "title": "üì¶ Amazon FBA: Business Intelligence Hub",
        "update_btn": "üîÑ –û–±–Ω–æ–≤–∏—Ç—å",
        "sidebar_title": "üîç –§–∏–ª—å—Ç—Ä—ã",
        "date_label": "üìÖ –î–∞—Ç–∞:",
        "store_label": "üè™ –ú–∞–≥–∞–∑–∏–Ω:",
        "all_stores": "–í—Å–µ",
        "total_sku": "–í—Å–µ–≥–æ SKU",
        "total_avail": "–®—Ç—É–∫ –Ω–∞ —Å–∫–ª–∞–¥–µ",
        "total_value": "üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å —Å–∫–ª–∞–¥–∞",
        "velocity_30": "–ü—Ä–æ–¥–∞–∂–∏ (30 –¥–Ω–µ–π)",
        "chart_value_treemap": "üí∞ –ì–¥–µ –¥–µ–Ω—å–≥–∏?",
        "chart_velocity": "üöÄ –°–∫–æ—Ä–æ—Å—Ç—å vs –û—Å—Ç–∞—Ç–∫–∏",
        "chart_age": "‚è≥ –í–æ–∑—Ä–∞—Å—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è",
        "top_money_sku": "üèÜ –¢–æ–ø SKU –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏",
        "top_qty_sku": "üèÜ –¢–æ–ø SKU –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É",
        "avg_price": "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞",
        "ai_header": "üß† AI –ü—Ä–æ–≥–Ω–æ–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤",
        "ai_select": "–í—ã–±–µ—Ä–∏—Ç–µ SKU:",
        "ai_days": "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞:",
        "ai_result_date": "üìÖ –î–∞—Ç–∞ Sold-out:",
        "ai_result_days": "–î–Ω–µ–π –æ—Å—Ç–∞–ª–æ—Å—å:",
        "ai_ok": "‚úÖ –ó–∞–ø–∞—Å–æ–≤ —Ö–≤–∞—Ç–∏—Ç",
        "ai_error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö",
        "footer_date": "üìÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã:",
        "download_excel": "üì• –°–∫–∞—á–∞—Ç—å Excel",
        "settlements_title": "üè¶ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤—ã–ø–ª–∞—Ç—ã (Settlements)",
        "net_payout": "–ß–∏—Å—Ç–∞—è –≤—ã–ø–ª–∞—Ç–∞",
        "gross_sales": "–í–∞–ª–æ–≤—ã–µ –ø—Ä–æ–¥–∞–∂–∏",
        "total_fees": "–í—Å–µ–≥–æ –∫–æ–º–∏—Å—Å–∏–π",
        "total_refunds": "–í–æ–∑–≤—Ä–∞—Ç—ã —Å—Ä–µ–¥—Å—Ç–≤",
        "chart_payout_trend": "üìâ –î–∏–Ω–∞–º–∏–∫–∞ –≤—ã–ø–ª–∞—Ç",
        "chart_fee_breakdown": "üí∏ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞—Å—Ö–æ–¥–æ–≤",
        "currency_select": "üí± –í–∞–ª—é—Ç–∞:",
        "sales_traffic_title": "üìà Sales & Traffic",
        "st_sessions": "–°–µ—Å—Å–∏–∏",
        "st_page_views": "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã",
        "st_units": "–ó–∞–∫–∞–∑–∞–Ω–æ —à—Ç—É–∫",
        "st_conversion": "–ö–æ–Ω–≤–µ—Ä—Å–∏—è",
        "st_revenue": "–î–æ—Ö–æ–¥",
        "st_buy_box": "Buy Box %",
        "reviews_title": "‚≠ê –û—Ç–∑—ã–≤—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π",
        "total_reviews": "–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤",
        "avg_review_rating": "–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥",
        "verified_pct": "–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (%)",
        "star_dist": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–≤–µ–∑–¥–∞–º",
        "worst_asin": "–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ ASIN (1-2‚òÖ)",
    }
}

# ============================================
# DATA LOADERS
# ============================================

@st.cache_data(ttl=60)
def load_data():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text("SELECT * FROM fba_inventory ORDER BY created_at DESC"), conn)
        return df
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î (Inventory): {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_orders():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM orders ORDER BY "Order Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=False, errors='coerce')
        column_mappings = {
            'Quantity':       ['Quantity', 'quantity', 'qty'],
            'Item Price':     ['Item Price', 'item-price', 'item_price', 'price'],
            'Item Tax':       ['Item Tax', 'item-tax', 'item_tax', 'tax'],
            'Shipping Price': ['Shipping Price', 'shipping-price', 'shipping_price', 'shipping'],
        }
        for target_col, possible_names in column_mappings.items():
            found = False
            for col_name in possible_names:
                if col_name in df.columns:
                    df[target_col] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)
                    found = True
                    break
            if not found:
                df[target_col] = 0
        df['Total Price'] = df['Item Price'] * df['Quantity']
        return df
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è orders: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_settlements():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM settlements ORDER BY "Posted Date" DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['Amount']      = pd.to_numeric(df['Amount'], errors='coerce').fillna(0.0)
        df['Quantity']    = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0)
        df['Posted Date'] = pd.to_datetime(df['Posted Date'], dayfirst=False, errors='coerce')
        if 'Currency' not in df.columns:
            df['Currency'] = 'USD'
        df = df.dropna(subset=['Posted Date'])
        return df
    except Exception as e:
        st.error(f"Error loading settlements: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=60)
def load_sales_traffic():
    import psycopg2
    import psycopg2.extras
    db_url = DATABASE_URL
    if not db_url:
        return pd.DataFrame()
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)
    conn = None
    try:
        conn = psycopg2.connect(db_url)
        cur  = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute("SELECT * FROM spapi.sales_traffic ORDER BY report_date DESC")
        rows    = cur.fetchall()
        columns = [desc[0] for desc in cur.description]
        cur.close()
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows, columns=columns)
        numeric_cols = [
            'sessions','page_views','units_ordered','units_ordered_b2b',
            'total_order_items','total_order_items_b2b',
            'ordered_product_sales','ordered_product_sales_b2b',
            'session_percentage','page_views_percentage',
            'buy_box_percentage','unit_session_percentage',
            'mobile_sessions','mobile_page_views',
            'browser_sessions','browser_page_views',
            'mobile_session_percentage','mobile_page_views_percentage',
            'mobile_unit_session_percentage','mobile_buy_box_percentage',
            'browser_session_percentage','browser_page_views_percentage',
            'browser_unit_session_percentage','browser_buy_box_percentage',
        ]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')
        if 'created_at' in df.columns:
            created = pd.to_datetime(df['created_at'], errors='coerce').dt.normalize()
            if df['report_date'].isna().all():
                df['report_date'] = created
            elif df['report_date'].isna().any():
                mask = df['report_date'].isna()
                df.loc[mask, 'report_date'] = created[mask]
        df['report_date'] = df['report_date'].dt.normalize()
        df = df.dropna(subset=['report_date'])
        return df
    except Exception:
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()


@st.cache_data(ttl=60)
def load_returns():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df_returns = pd.read_sql(text('SELECT * FROM returns ORDER BY "Return Date" DESC'), conn)
            df_orders  = pd.read_sql(text("SELECT * FROM orders"), conn)
        return df_returns, df_orders
    except Exception:
        return pd.DataFrame(), pd.DataFrame()


@st.cache_data(ttl=60)
def load_reviews():
    try:
        engine = get_engine()
        with engine.connect() as conn:
            df = pd.read_sql(text('SELECT * FROM amazon_reviews ORDER BY review_date DESC'), conn)
        if df.empty:
            return pd.DataFrame()
        df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')
        df['rating']      = pd.to_numeric(df['rating'], errors='coerce').fillna(0).astype(int)
        if 'is_verified' in df.columns:
            df['is_verified'] = df['is_verified'].astype(bool)
        return df
    except Exception:
        return pd.DataFrame()


# ============================================
# HELPERS
# ============================================

def insight_card(emoji, title, text, color="#1e1e2e"):
    st.markdown(f"""
    <div style="background:{color};border-left:4px solid #4472C4;border-radius:8px;
                padding:14px 18px;margin-bottom:10px;">
        <div style="font-size:16px;font-weight:700;color:#fff;margin-bottom:4px;">{emoji} {title}</div>
        <div style="font-size:14px;color:#ccc;line-height:1.5;">{text}</div>
    </div>""", unsafe_allow_html=True)


def balanced_reviews(df, max_per_star=100):
    """Up to max_per_star reviews per rating level (1-5). Max 500 total."""
    parts = [df[df['rating'] == s].head(max_per_star) for s in [1, 2, 3, 4, 5]]
    return pd.concat(parts, ignore_index=True) if parts else df


# ============================================
# INSIGHT FUNCTIONS
# ============================================

def insights_sales_traffic(df_filtered, asin_stats):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_sessions = int(df_filtered['sessions'].sum())
    total_units    = int(df_filtered['units_ordered'].sum())
    total_revenue  = df_filtered['ordered_product_sales'].sum()
    avg_conv       = (total_units / total_sessions * 100) if total_sessions > 0 else 0
    avg_buy_box    = df_filtered['buy_box_percentage'].mean()
    mob            = df_filtered['mobile_sessions'].sum() if 'mobile_sessions' in df_filtered.columns else 0
    bro            = df_filtered['browser_sessions'].sum() if 'browser_sessions' in df_filtered.columns else 0
    mobile_pct     = (mob / (mob + bro) * 100) if (mob + bro) > 0 else 0
    avg_conv_all   = asin_stats['Conv %'].median()
    low_conv       = asin_stats[(asin_stats['Sessions'] > asin_stats['Sessions'].median()) & (asin_stats['Conv %'] < avg_conv_all)]
    low_bb         = asin_stats[asin_stats['Buy Box %'] < 80]
    rev_per_sess   = total_revenue / total_sessions if total_sessions > 0 else 0
    cols = st.columns(2)
    i = 0
    if avg_conv >= 12:   txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –≤—ã—à–µ –Ω–æ—Ä–º—ã. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–π —Ä–µ–∫–ª–∞–º—É!", "üü¢", "#0d2b1e"
    elif avg_conv >= 8:  txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –≤ –Ω–æ—Ä–º–µ. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —á–µ—Ä–µ–∑ A+.", "üü°", "#2b2400"
    else:                txt, em, col = f"–ö–æ–Ω–≤–µ—Ä—Å–∏—è <b>{avg_conv:.1f}%</b> ‚Äî –Ω–∏–∂–µ –Ω–æ—Ä–º—ã. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ç–æ –∏ —Ü–µ–Ω—É.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ö–æ–Ω–≤–µ—Ä—Å–∏—è", txt, col); i+=1
    if avg_buy_box >= 95:  txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ!", "üü¢", "#0d2b1e"
    elif avg_buy_box >= 80: txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –Ω–æ—Ä–º–∞. {len(low_bb)} ASIN–æ–≤ —Ç–µ—Ä—è—é—Ç.", "üü°", "#2b2400"
    else:                   txt, em, col = f"Buy Box <b>{avg_buy_box:.1f}%</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–ø—Ä–∞–π—Å–µ—Ä.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "Buy Box", txt, col); i+=1
    txt = f"<b>{mobile_pct:.0f}%</b> –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ {'‚Äî –Ω–æ—Ä–º–∞.' if mobile_pct >= 60 else '‚Äî –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ ~65%.'}"
    with cols[i%2]: insight_card("üì±", "–ú–æ–±–∞–π–ª", txt, "#1a1a2e"); i+=1
    if len(low_conv) > 0:
        top = low_conv.nlargest(1,'Sessions').iloc[0]
        txt, em, col = f"<b>{len(low_conv)} ASIN–æ–≤</b> —Å –≤—ã—Å–æ–∫–∏–º —Ç—Ä–∞—Ñ–∏–∫–æ–º –∏ –Ω–∏–∑–∫–æ–π –∫–æ–Ω–≤–µ—Ä—Å–∏–µ–π. –ö—Ä–∏—Ç–∏—á–Ω—ã–π: <b>{top['ASIN']}</b>.", "üî¥", "#2b0d0d"
    else: txt, em, col = "–í—Å–µ ASIN—ã —Å –≤—ã—Å–æ–∫–∏–º —Ç—Ä–∞—Ñ–∏–∫–æ–º –∫–æ–Ω–≤–µ—Ä—Ç—è—Ç —Ö–æ—Ä–æ—à–æ!", "üü¢", "#0d2b1e"
    with cols[i%2]: insight_card(em, "–£–ø—É—â–µ–Ω–Ω–∞—è –≤—ã—Ä—É—á–∫–∞", txt, col); i+=1
    with cols[i%2]: insight_card("üí°", "–¶–µ–Ω–∞ —Å–µ—Å—Å–∏–∏", f"–ö–∞–∂–¥–∞—è —Å–µ—Å—Å–∏—è ‚Üí <b>${rev_per_sess:.2f}</b>. +1000 —Å–µ—Å—Å–∏–π = +${rev_per_sess*1000:,.0f}.", "#1a1a2e"); i+=1
    if not asin_stats.empty:
        top = asin_stats.nlargest(1,'Revenue').iloc[0]
        top_pct = top['Revenue']/total_revenue*100 if total_revenue > 0 else 0
        with cols[i%2]: insight_card("üèÜ", "–ì–ª–∞–≤–Ω—ã–π ASIN", f"<b>{top['ASIN']}</b> = ${top['Revenue']:,.0f} ({top_pct:.0f}%).", "#1a2b1e")


def insights_settlements(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    net     = df_filtered['Amount'].sum()
    gross   = df_filtered[(df_filtered['Transaction Type']=='Order')&(df_filtered['Amount']>0)]['Amount'].sum()
    fees    = df_filtered[(df_filtered['Amount']<0)&(df_filtered['Transaction Type']!='Refund')&(~df_filtered['Transaction Type'].str.lower().str.contains('other',na=False))]['Amount'].sum()
    refunds = df_filtered[df_filtered['Transaction Type']=='Refund']['Amount'].sum()
    fee_pct    = abs(fees)/gross*100 if gross>0 else 0
    refund_pct = abs(refunds)/gross*100 if gross>0 else 0
    margin_pct = net/gross*100 if gross>0 else 0
    cols = st.columns(2); i = 0
    if margin_pct >= 30:  txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ!", "üü¢", "#0d2b1e"
    elif margin_pct >= 15: txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –Ω–æ—Ä–º–∞ –¥–ª—è FBA.", "üü°", "#2b2400"
    else:                  txt, em, col = f"–ú–∞—Ä–∂–∞ <b>{margin_pct:.1f}%</b> ‚Äî –Ω–∏–∑–∫–æ! –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞—Å—Ö–æ–¥—ã.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ß–∏—Å—Ç–∞—è –º–∞—Ä–∂–∞", txt, col); i+=1
    if fee_pct <= 30:  txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî –≤ –Ω–æ—Ä–º–µ.", "üü¢", "#0d2b1e"
    elif fee_pct <= 40: txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî –Ω–µ–º–Ω–æ–≥–æ –≤—ã—Å–æ–∫–æ.", "üü°", "#2b2400"
    else:               txt, em, col = f"–ö–æ–º–∏—Å—Å–∏–∏ <b>{fee_pct:.1f}%</b> ‚Äî —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–ù–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–∏—Å—Å–∏–π", txt, col); i+=1
    if refund_pct <= 3:  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ.", "üü¢", "#0d2b1e"
    elif refund_pct <= 8: txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî —É–º–µ—Ä–µ–Ω–Ω–æ.", "üü°", "#2b2400"
    else:                 txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{refund_pct:.1f}%</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–í–æ–∑–≤—Ä–∞—Ç—ã", txt, col); i+=1
    with cols[i%2]: insight_card("üí∞", "–ò—Ç–æ–≥", f"–ü—Ä–æ–¥–∞–∂–∏ <b>${gross:,.0f}</b> ‚Üí –Ω–∞ —Ä—É–∫–∏ <b>${net:,.0f}</b>. –ö–æ–º–∏—Å—Å–∏–∏: ${abs(fees):,.0f}.", "#1a1a2e")


def insights_returns(df_filtered, return_rate):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_val  = df_filtered['Return Value'].sum()
    top_reason = df_filtered['Reason'].value_counts().index[0] if 'Reason' in df_filtered.columns and not df_filtered.empty else None
    top_sku    = df_filtered['SKU'].value_counts().index[0] if not df_filtered.empty else None
    cols = st.columns(2); i = 0
    if return_rate <= 3:  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ.", "üü¢", "#0d2b1e"
    elif return_rate <= 8: txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –ø—Ä–∏–µ–º–ª–µ–º–æ.", "üü°", "#2b2400"
    else:                  txt, em, col = f"–í–æ–∑–≤—Ä–∞—Ç—ã <b>{return_rate:.1f}%</b> ‚Äî –æ–ø–∞—Å–Ω–æ!", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em, "–£—Ä–æ–≤–µ–Ω—å –≤–æ–∑–≤—Ä–∞—Ç–æ–≤", txt, col); i+=1
    with cols[i%2]: insight_card("üí∏", "–£—â–µ—Ä–±", f"–í–æ–∑–≤—Ä–∞—Ç—ã —Å—Ç–æ—è—Ç <b>${total_val:,.0f}</b>.", "#2b1a00"); i+=1
    if top_reason:
        with cols[i%2]: insight_card("üîç", "–ì–ª–∞–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞", f"<b>¬´{top_reason}¬ª</b>", "#1a1a2e"); i+=1
    if top_sku:
        count = df_filtered['SKU'].value_counts().iloc[0]
        with cols[i%2]: insight_card("‚ö†Ô∏è", "–ü—Ä–æ–±–ª–µ–º–Ω—ã–π SKU", f"<b>{top_sku}</b> ({count} –≤–æ–∑–≤—Ä–∞—Ç–æ–≤).", "#2b0d0d")


def insights_inventory(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_val   = df_filtered['Stock Value'].sum()
    total_units = df_filtered['Available'].sum()
    avg_vel     = df_filtered['Velocity'].mean() if 'Velocity' in df_filtered.columns else 0
    top_frozen  = df_filtered.nlargest(1,'Stock Value').iloc[0] if not df_filtered.empty else None
    dead_stock  = df_filtered[df_filtered['Velocity']==0] if 'Velocity' in df_filtered.columns else pd.DataFrame()
    cols = st.columns(2); i = 0
    months = int(total_units/avg_vel/30) if avg_vel > 0 else 0
    with cols[i%2]: insight_card("üßä","–ó–∞–º–æ—Ä–æ–∑–∫–∞ –∫–∞–ø–∏—Ç–∞–ª–∞",f"–ó–∞–º–æ—Ä–æ–∂–µ–Ω–æ <b>${total_val:,.0f}</b>. –ó–∞–ø–∞—Å –Ω–∞ {months if avg_vel>0 else '‚àû'} –º–µ—Å.","#1a1a2e"); i+=1
    if top_frozen is not None:
        pct = top_frozen['Stock Value']/total_val*100 if total_val > 0 else 0
        with cols[i%2]: insight_card("üè¶","–ì–ª–∞–≤–Ω—ã–π –∞–∫—Ç–∏–≤",f"<b>{top_frozen['SKU']}</b> –¥–µ—Ä–∂–∏—Ç ${top_frozen['Stock Value']:,.0f} ({pct:.0f}%).","#1a2b1e"); i+=1
    if len(dead_stock) > 0:
        dead_val = dead_stock['Stock Value'].sum()
        with cols[i%2]: insight_card("‚ò†Ô∏è","–ú—ë—Ä—Ç–≤—ã–π —Å—Ç–æ–∫",f"<b>{len(dead_stock)} SKU</b> –±–µ–∑ –ø—Ä–æ–¥–∞–∂ ‚Äî ${dead_val:,.0f}. –†–∞—Å—Å–º–æ—Ç—Ä–∏ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—é.","#2b0d0d"); i+=1
    days = int(total_units/(avg_vel*30)*30) if avg_vel > 0 else 999
    if days <= 30:   txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî —Ä–∏—Å–∫ out of stock!", "üî¥", "#2b0d0d"
    elif days <= 60: txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî –ø–ª–∞–Ω–∏—Ä—É–π –ø–æ—Å—Ç–∞–≤–∫—É.", "üü°", "#2b2400"
    else:            txt, em, col = f"–ó–∞–ø–∞—Å–æ–≤ –Ω–∞ <b>{days} –¥–Ω–µ–π</b> ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.", "üü¢", "#0d2b1e"
    with cols[i%2]: insight_card(em,"–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å",txt,col)


def insights_orders(df_filtered):
    st.markdown("---")
    st.markdown("### üß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã")
    total_rev    = df_filtered['Total Price'].sum()
    total_orders = df_filtered['Order ID'].nunique()
    avg_order    = total_rev/total_orders if total_orders > 0 else 0
    days         = max((df_filtered['Order Date'].max()-df_filtered['Order Date'].min()).days,1)
    rev_per_day  = total_rev/days
    top_sku      = df_filtered.groupby('SKU')['Total Price'].sum().nlargest(1)
    cols = st.columns(2); i = 0
    with cols[i%2]: insight_card("üõí","–°—Ä–µ–¥–Ω–∏–π —á–µ–∫",f"<b>${avg_order:.2f}</b>. +10% –∫ AOV = +${total_rev*0.1:,.0f}.","#1a1a2e"); i+=1
    with cols[i%2]: insight_card("üìà","–î–Ω–µ–≤–Ω–∞—è –≤—ã—Ä—É—á–∫–∞",f"<b>${rev_per_day:,.0f}/–¥–µ–Ω—å</b>. –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –º–µ—Å—è—Ü: ${rev_per_day*30:,.0f}.","#1a2b1e"); i+=1
    if not top_sku.empty:
        sku_name, sku_rev = top_sku.index[0], top_sku.iloc[0]
        pct = sku_rev/total_rev*100 if total_rev > 0 else 0
        with cols[i%2]: insight_card("‚ö°","–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Ä–∏—Å–∫–∞",f"<b>{sku_name}</b> = {pct:.0f}% (${sku_rev:,.0f}). –î–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä—É–π.","#2b1a00")


def insights_reviews(df, asin=None):
    st.markdown("---")
    label = f"ASIN {asin}" if asin else "–≤—Å–µ–º ASIN–∞–º"
    st.markdown(f"### üß† –ò–Ω—Å–∞–π—Ç—ã –ø–æ {label}")
    total = len(df)
    if total == 0:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Å–∞–π—Ç–æ–≤.")
        return
    avg_rating = df['rating'].mean()
    neg_df     = df[df['rating'] <= 2]
    pos_df     = df[df['rating'] >= 4]
    neg_pct    = len(neg_df)/total*100
    pos_pct    = len(pos_df)/total*100
    cols = st.columns(2); i = 0
    if avg_rating >= 4.4:   txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –æ—Ç–ª–∏—á–Ω–æ! –°–∏–ª—å–Ω–æ–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–µ –¥–æ–≤–µ—Ä–∏–µ.", "üü¢", "#0d2b1e"
    elif avg_rating >= 4.0: txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –Ω–æ—Ä–º–∞, —Ä–∏—Å–∫ —É–ø–∞—Å—Ç—å –Ω–∏–∂–µ 4.0.", "üü°", "#2b2400"
    else:                   txt, em, col = f"–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª <b>{avg_rating:.1f}‚òÖ</b> ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –†–µ–∂–µ—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏—é –∏ —É–¥–æ—Ä–æ–∂–∞–µ—Ç PPC.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em,"–ó–¥–æ—Ä–æ–≤—å–µ —Ä–µ–π—Ç–∏–Ω–≥–∞",txt,col); i+=1
    if neg_pct <= 10:  txt, em, col = f"–í—Å–µ–≥–æ <b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö (1-2‚òÖ). –ü—Ä–æ–¥—É–∫—Ç –æ–ø—Ä–∞–≤–¥—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è.", "üü¢", "#0d2b1e"
    elif neg_pct <= 20: txt, em, col = f"<b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö ‚Äî —Å–∏—Å—Ç–µ–º–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞. –ß–∏—Ç–∞–π —Ç–µ–∫—Å—Ç—ã 1‚òÖ.", "üü°", "#2b2400"
    else:               txt, em, col = f"<b>{neg_pct:.1f}%</b> –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ! –°—Ä–æ—á–Ω–æ —Ñ–∏–∫—Å–∏ –ø—Ä–æ–¥—É–∫—Ç –∏–ª–∏ –ª–∏—Å—Ç–∏–Ω–≥.", "üî¥", "#2b0d0d"
    with cols[i%2]: insight_card(em,"–£—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞",txt,col); i+=1
    with cols[i%2]: insight_card("üíö","–õ–æ—è–ª—å–Ω–æ—Å—Ç—å",f"<b>{pos_pct:.1f}%</b> –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö (4-5‚òÖ). –ë–∞–∑–∞ –ª–æ—è–ª—å–Ω—ã—Ö –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π.","#0d2b1e" if pos_pct>=70 else "#2b2400"); i+=1
    if 'is_verified' in df.columns:
        ver_pct = df['is_verified'].mean()*100
        with cols[i%2]: insight_card("‚úÖ","–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è",f"<b>{ver_pct:.1f}%</b> –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã {'‚Äî –≤—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ —É Amazon.' if ver_pct>=80 else '‚Äî —Å–ª–µ–¥–∏ –∑–∞ –ø–æ–ª–∏—Ç–∏–∫–æ–π.'}","#1a1a2e"); i+=1
    if asin is None and not neg_df.empty and 'asin' in neg_df.columns:
        worst = neg_df['asin'].value_counts()
        if not worst.empty:
            with cols[i%2]: insight_card("‚ö†Ô∏è","–¢–æ–∫—Å–∏—á–Ω—ã–π ASIN",f"<b>{worst.index[0]}</b> ‚Äî {worst.iloc[0]} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö. –ù–∞—á–Ω–∏ –∞–Ω–∞–ª–∏–∑ —Å –Ω–µ–≥–æ.","#2b0d0d")


# ============================================
# OVERVIEW CONSOLIDATED INSIGHTS
# ============================================

def show_overview_insights(df_inventory):
    st.markdown("---")
    st.markdown("## üß† Business Intelligence: –ó–≤–µ–¥–µ–Ω—ñ —ñ–Ω—Å–∞–π—Ç–∏")
    st.caption("–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –≤—Å—ñ—Ö –º–æ–¥—É–ª—ñ–≤")

    df_settlements = load_settlements()
    df_st          = load_sales_traffic()
    df_orders      = load_orders()
    df_ret_raw, df_ord_raw = load_returns()
    df_reviews     = load_reviews()

    df_returns  = pd.DataFrame()
    return_rate = 0
    if not df_ret_raw.empty:
        df_ret = df_ret_raw.copy()
        df_ret['Return Date'] = pd.to_datetime(df_ret['Return Date'], errors='coerce')
        if 'Price' not in df_ret.columns and not df_ord_raw.empty:
            for col in ['Item Price','item-price','item_price','price','Price']:
                if col in df_ord_raw.columns:
                    df_ord_raw[col] = pd.to_numeric(df_ord_raw[col], errors='coerce')
                    df_ret['Price'] = df_ret['SKU'].map(df_ord_raw.groupby('SKU')[col].mean()).fillna(0)
                    break
        if 'Price' not in df_ret.columns: df_ret['Price'] = 0
        df_ret['Price']        = pd.to_numeric(df_ret['Price'], errors='coerce').fillna(0)
        df_ret['Quantity']     = pd.to_numeric(df_ret.get('Quantity',1), errors='coerce').fillna(1)
        df_ret['Return Value'] = df_ret['Price'] * df_ret['Quantity']
        df_returns = df_ret
        if not df_ord_raw.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_ord_raw.columns:
                    total_orders = df_ord_raw[col].nunique()
                    unique_ret   = df_returns['Order ID'].nunique() if 'Order ID' in df_returns.columns else 0
                    return_rate  = unique_ret/total_orders*100 if total_orders > 0 else 0
                    break

    tabs = st.tabs(["üí∞ Inventory","üè¶ Settlements","üìà Sales & Traffic","üõí Orders","üì¶ Returns","‚≠ê Reviews"])

    with tabs[0]:
        if not df_inventory.empty and 'Stock Value' in df_inventory.columns:
            insights_inventory(df_inventory)
        else: st.info("üì¶ –î–∞–Ω—ñ –ø–æ —ñ–Ω–≤–µ–Ω—Ç–∞—Ä—é –≤—ñ–¥—Å—É—Ç–Ω—ñ")

    with tabs[1]:
        if not df_settlements.empty:
            max_d  = df_settlements['Posted Date'].max()
            df_s30 = df_settlements[df_settlements['Posted Date'] >= max_d - dt.timedelta(days=30)]
            insights_settlements(df_s30 if not df_s30.empty else df_settlements)
        else: st.info("üè¶ –î–∞–Ω—ñ –ø–æ –≤–∏–ø–ª–∞—Ç–∞—Ö –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[2]:
        if not df_st.empty:
            max_d   = df_st['report_date'].max()
            df_use  = df_st[df_st['report_date'] >= max_d - dt.timedelta(days=14)]
            df_use  = df_use if not df_use.empty else df_st
            asin_col = 'child_asin' if 'child_asin' in df_use.columns else df_use.columns[0]
            as_ = df_use.groupby(asin_col).agg({'sessions':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
            as_.columns = ['ASIN','Sessions','Units','Revenue','Buy Box %']
            as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
            insights_sales_traffic(df_use, as_)
        else: st.info("üìà –î–∞–Ω—ñ Sales & Traffic –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[3]:
        if not df_orders.empty:
            max_d  = df_orders['Order Date'].max()
            df_o30 = df_orders[df_orders['Order Date'] >= max_d - dt.timedelta(days=30)]
            insights_orders(df_o30 if not df_o30.empty else df_orders)
        else: st.info("üõí –î–∞–Ω—ñ –∑–∞–º–æ–≤–ª–µ–Ω—å –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[4]:
        if not df_returns.empty:
            max_d  = df_returns['Return Date'].max()
            df_r30 = df_returns[df_returns['Return Date'] >= max_d - dt.timedelta(days=30)]
            insights_returns(df_r30 if not df_r30.empty else df_returns, return_rate)
        else: st.info("üì¶ –î–∞–Ω—ñ –ø–æ–≤–µ—Ä–Ω–µ–Ω—å –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    with tabs[5]:
        if not df_reviews.empty: insights_reviews(df_reviews, asin=None)
        else: st.info("‚≠ê –î–∞–Ω—ñ –≤—ñ–¥–≥—É–∫—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ.")


# ============================================
# REVIEWS MODULE
# ============================================

def show_reviews(t):
    df_all = load_reviews()
    if df_all.empty:
        st.warning("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–∏—Ö –ø—Ä–æ –≤—ñ–¥–≥—É–∫–∏. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ ETL-—Å–∫—Ä–∏–ø—Ç (Apify ‚Üí Postgres).")
        return

    # Sidebar filters
    st.sidebar.markdown("---")
    st.sidebar.subheader("‚≠ê –§—ñ–ª—å—Ç—Ä–∏ –≤—ñ–¥–≥—É–∫—ñ–≤")
    asins = sorted(df_all['asin'].dropna().unique().tolist()) if 'asin' in df_all.columns else []
    asin_options  = ['üåê –í—Å—ñ ASIN–∏'] + asins
    sel_raw       = st.sidebar.selectbox("üì¶ ASIN:", asin_options, key="rev_asin")
    selected_asin = None if sel_raw == 'üåê –í—Å—ñ ASIN–∏' else sel_raw
    star_filter   = st.sidebar.multiselect("‚≠ê –†–µ–π—Ç–∏–Ω–≥ (—Ñ—ñ–ª—å—Ç—Ä):", [5, 4, 3, 2, 1], default=[], key="rev_stars")

    # Apply
    df = df_all.copy()
    if selected_asin:
        df = df[df['asin'] == selected_asin]
    if star_filter:
        df = df[df['rating'].isin(star_filter)]
    if df.empty:
        st.warning("–ù–µ–º–∞—î –≤—ñ–¥–≥—É–∫—ñ–≤ –∑–∞ —Ü–∏–º–∏ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏.")
        return

    # Header
    asin_label = selected_asin if selected_asin else "–í—Å—ñ ASIN–∏"
    st.markdown(f"### {t['reviews_title']} ‚Äî {asin_label}")

    total_revs   = len(df)
    avg_rating   = df['rating'].mean()
    verified_pct = df['is_verified'].mean()*100 if 'is_verified' in df.columns and total_revs > 0 else 0
    neg_count    = int((df['rating'] <= 2).sum())
    pos_count    = int((df['rating'] >= 4).sum())

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric(t["total_reviews"],     f"{total_revs:,}")
    c2.metric(t["avg_review_rating"], f"{avg_rating:.2f} ‚≠ê")
    c3.metric(t["verified_pct"],      f"{verified_pct:.1f}%")
    c4.metric("üî¥ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö (1-2‚òÖ)", f"{neg_count:,}")
    c5.metric("üü¢ –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö (4-5‚òÖ)", f"{pos_count:,}")

    st.markdown("---")

    # ---- OVERVIEW MODE: all ASINs comparison ----
    if selected_asin is None and 'asin' in df.columns:
        st.markdown("### üìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è ASIN—ñ–≤")

        asin_stats = df.groupby('asin').agg(
            Reviews=('rating','count'),
            Rating=('rating','mean'),
            Neg=('rating', lambda x: (x<=2).sum()),
            Pos=('rating', lambda x: (x>=4).sum()),
        ).reset_index()
        asin_stats.columns = ['ASIN','–í—ñ–¥–≥—É–∫—ñ–≤','–†–µ–π—Ç–∏–Ω–≥','–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö','–ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö']
        asin_stats['Neg %'] = (asin_stats['–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö']/asin_stats['–í—ñ–¥–≥—É–∫—ñ–≤']*100).round(1)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ‚≠ê –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ ASIN–∞—Ö")
            asin_sort = asin_stats.sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)
            colors = ['#F44336' if r<4.0 else '#FFC107' if r<4.4 else '#4CAF50' for r in asin_sort['–†–µ–π—Ç–∏–Ω–≥']]
            fig = go.Figure(go.Bar(
                x=asin_sort['–†–µ–π—Ç–∏–Ω–≥'], y=asin_sort['ASIN'], orientation='h',
                marker_color=colors,
                text=[f"{v:.2f}‚òÖ" for v in asin_sort['–†–µ–π—Ç–∏–Ω–≥']], textposition='outside'
            ))
            fig.add_vline(x=4.0, line_dash="dash", line_color="orange", annotation_text="–ü–æ—Ä—ñ–≥ 4.0")
            fig.update_layout(height=max(300, len(asin_sort)*38), xaxis_range=[1, 5.5])
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.markdown("#### üî¥ % –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –ø–æ ASIN–∞—Ö")
            asin_neg = asin_stats.sort_values('Neg %', ascending=False)
            neg_colors = ['#F44336' if v>20 else '#FFC107' if v>10 else '#4CAF50' for v in asin_neg['Neg %']]
            fig2 = go.Figure(go.Bar(
                x=asin_neg['Neg %'], y=asin_neg['ASIN'], orientation='h',
                marker_color=neg_colors,
                text=[f"{v:.1f}%" for v in asin_neg['Neg %']], textposition='outside'
            ))
            fig2.update_layout(height=max(300, len(asin_neg)*38))
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("#### üìã –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –ø–æ ASIN–∞—Ö")
        st.dataframe(
            asin_stats.sort_values('–†–µ–π—Ç–∏–Ω–≥').style
                .format({'–†–µ–π—Ç–∏–Ω–≥':'{:.2f}', 'Neg %':'{:.1f}%'})
                .background_gradient(subset=['–†–µ–π—Ç–∏–Ω–≥'], cmap='RdYlGn')
                .background_gradient(subset=['Neg %'],   cmap='RdYlGn_r'),
            use_container_width=True
        )

        # ---- Variant breakdown by product_attributes ----
        if 'product_attributes' in df.columns:
            st.markdown("---")
            st.markdown("### üé® –Ø–∫—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ (Size / Color) –∑–±–∏—Ä–∞—é—Ç—å –Ω–µ–≥–∞—Ç–∏–≤?")
            st.caption("–ü–∞—Ä—Å–∏–º–æ product_attributes ‚Üí –±–∞—á–∏–º–æ –ø—Ä–æ–±–ª–µ–º–Ω—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó")

            df_attr = df.copy()
            df_attr['product_attributes'] = df_attr['product_attributes'].fillna('').astype(str)

            def parse_attr(s):
                """Extract Size and Color from attribute string like 'Size: X-Large, Color: 250 Navy'"""
                size, color = None, None
                for part in s.split(','):
                    part = part.strip()
                    if part.lower().startswith('size:'):
                        size = part.split(':', 1)[1].strip()
                    elif part.lower().startswith('color:'):
                        color = part.split(':', 1)[1].strip()
                return pd.Series({'Size': size or 'N/A', 'Color': color or 'N/A'})

            parsed = df_attr['product_attributes'].apply(parse_attr)
            df_attr = pd.concat([df_attr.reset_index(drop=True), parsed], axis=1)

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### üìè –†–µ–π—Ç–∏–Ω–≥ –ø–æ Size")
                size_stats = df_attr[df_attr['Size'] != 'N/A'].groupby('Size').agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating','count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating','mean'),
                    Neg=('rating', lambda x: (x<=2).sum()),
                ).reset_index()
                size_stats['Neg %'] = (size_stats['Neg']/size_stats['–í—ñ–¥–≥—É–∫—ñ–≤']*100).round(1)
                size_stats = size_stats[size_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3].sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)

                if not size_stats.empty:
                    colors_s = ['#F44336' if r<3.5 else '#FFC107' if r<4.2 else '#4CAF50' for r in size_stats['–†–µ–π—Ç–∏–Ω–≥']]
                    fig_size = go.Figure(go.Bar(
                        x=size_stats['–†–µ–π—Ç–∏–Ω–≥'], y=size_stats['Size'], orientation='h',
                        marker_color=colors_s,
                        text=[f"{r:.2f}‚òÖ ({n:.0f}% neg, {v} –≤—ñ–¥–≥.)" for r,n,v in zip(size_stats['–†–µ–π—Ç–∏–Ω–≥'], size_stats['Neg %'], size_stats['–í—ñ–¥–≥—É–∫—ñ–≤'])],
                        textposition='outside',
                    ))
                    fig_size.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_size.update_layout(height=max(280, len(size_stats)*40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_size, use_container_width=True)
                else:
                    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø–æ —Ä–æ–∑–º—ñ—Ä–∞—Ö")

            with col2:
                st.markdown("#### üé® –†–µ–π—Ç–∏–Ω–≥ –ø–æ Color")
                color_stats = df_attr[df_attr['Color'] != 'N/A'].groupby('Color').agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating','count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating','mean'),
                    Neg=('rating', lambda x: (x<=2).sum()),
                ).reset_index()
                color_stats['Neg %'] = (color_stats['Neg']/color_stats['–í—ñ–¥–≥—É–∫—ñ–≤']*100).round(1)
                color_stats = color_stats[color_stats['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3].sort_values('–†–µ–π—Ç–∏–Ω–≥', ascending=True)

                if not color_stats.empty:
                    colors_c = ['#F44336' if r<3.5 else '#FFC107' if r<4.2 else '#4CAF50' for r in color_stats['–†–µ–π—Ç–∏–Ω–≥']]
                    fig_color = go.Figure(go.Bar(
                        x=color_stats['–†–µ–π—Ç–∏–Ω–≥'], y=color_stats['Color'], orientation='h',
                        marker_color=colors_c,
                        text=[f"{r:.2f}‚òÖ ({n:.0f}% neg, {v} –≤—ñ–¥–≥.)" for r,n,v in zip(color_stats['–†–µ–π—Ç–∏–Ω–≥'], color_stats['Neg %'], color_stats['–í—ñ–¥–≥—É–∫—ñ–≤'])],
                        textposition='outside',
                    ))
                    fig_color.add_vline(x=4.0, line_dash="dash", line_color="orange")
                    fig_color.update_layout(height=max(280, len(color_stats)*40), xaxis_range=[1, 5.8])
                    st.plotly_chart(fig_color, use_container_width=True)
                else:
                    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø–æ –∫–æ–ª—å–æ—Ä–∞—Ö")

            # Top problem variants table
            st.markdown("#### ‚ö†Ô∏è –¢–æ–ø –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ (—Ä–µ–π—Ç–∏–Ω–≥ < 4.0, –º—ñ–Ω. 3 –≤—ñ–¥–≥—É–∫–∏)")
            df_variants = df_attr[df_attr['Size'] != 'N/A'].copy()
            if 'asin' in df_variants.columns:
                var_group = df_variants.groupby(['asin','Size','Color']).agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating','count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating','mean'),
                    Neg=('rating', lambda x: (x<=2).sum()),
                ).reset_index()
            else:
                var_group = df_variants.groupby(['Size','Color']).agg(
                    –í—ñ–¥–≥—É–∫—ñ–≤=('rating','count'),
                    –†–µ–π—Ç–∏–Ω–≥=('rating','mean'),
                    Neg=('rating', lambda x: (x<=2).sum()),
                ).reset_index()

            var_group['Neg %'] = (var_group['Neg']/var_group['–í—ñ–¥–≥—É–∫—ñ–≤']*100).round(1)
            problem_variants = var_group[
                (var_group['–†–µ–π—Ç–∏–Ω–≥'] < 4.0) & (var_group['–í—ñ–¥–≥—É–∫—ñ–≤'] >= 3)
            ].sort_values('Neg %', ascending=False).head(20)

            if not problem_variants.empty:
                st.dataframe(
                    problem_variants.style
                        .format({'–†–µ–π—Ç–∏–Ω–≥':'{:.2f}', 'Neg %':'{:.1f}%'})
                        .background_gradient(subset=['–†–µ–π—Ç–∏–Ω–≥'], cmap='RdYlGn')
                        .background_gradient(subset=['Neg %'],   cmap='RdYlGn_r'),
                    use_container_width=True
                )
                st.caption("üí° –¶—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó ‚Äî –∫–∞–Ω–¥–∏–¥–∞—Ç–∏ –Ω–∞ –∑–º—ñ–Ω—É —Ä–æ–∑–º—ñ—Ä–Ω–æ—ó —Å—ñ—Ç–∫–∏, –ø–µ—Ä–µ–æ–ø–∏—Å –∞–±–æ –∑—É–ø–∏–Ω–∫—É –≤—ñ–¥–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")
            else:
                st.success("üéâ –í—Å—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –º–∞—é—Ç—å —Ä–µ–π—Ç–∏–Ω–≥ ‚â• 4.0 –∞–±–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –≤—ñ–¥–≥—É–∫—ñ–≤ –¥–ª—è –≤–∏—Å–Ω–æ–≤–∫—ñ–≤")

        st.markdown("---")
        st.markdown("### üìä –ó–∞–≥–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –∑—ñ—Ä–æ–∫")

    # ---- Star distribution + worst ASINs ----
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"#### {t['star_dist']}")
        star_counts = df['rating'].value_counts().reindex([5,4,3,2,1]).fillna(0).reset_index()
        star_counts.columns = ['–ó—ñ—Ä–∫–∏','–ö—ñ–ª—å–∫—ñ—Å—Ç—å']
        star_counts['label'] = star_counts['–ó—ñ—Ä–∫–∏'].astype(str) + '‚òÖ'
        color_map = {5:'#4CAF50',4:'#8BC34A',3:'#FFC107',2:'#FF9800',1:'#F44336'}
        fig_stars = go.Figure(go.Bar(
            x=star_counts['–ö—ñ–ª—å–∫—ñ—Å—Ç—å'], y=star_counts['label'], orientation='h',
            marker_color=[color_map.get(int(s),'#888') for s in star_counts['–ó—ñ—Ä–∫–∏']],
            text=star_counts['–ö—ñ–ª—å–∫—ñ—Å—Ç—å'], textposition='outside'
        ))
        fig_stars.update_layout(
            yaxis=dict(categoryorder='array', categoryarray=['1‚òÖ','2‚òÖ','3‚òÖ','4‚òÖ','5‚òÖ']),
            height=300, margin=dict(l=10,r=40,t=20,b=20)
        )
        st.plotly_chart(fig_stars, use_container_width=True)

    with col2:
        st.markdown(f"#### {t['worst_asin']}")
        bad = df_all[df_all['rating'] <= 2]
        if 'asin' in bad.columns and not bad.empty:
            bad_asins = bad['asin'].value_counts().head(8).reset_index()
            bad_asins.columns = ['ASIN','–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö']
            fig_bad = px.bar(bad_asins, x='ASIN', y='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö', text='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö',
                             color='–ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö', color_continuous_scale='Reds')
            fig_bad.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_bad, use_container_width=True)
        else:
            st.success("üéâ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –≤—ñ–¥–≥—É–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")

    # ---- Insights ----
    insights_reviews(df, asin=selected_asin)

    # ---- Balanced table ----
    st.markdown("---")
    st.markdown("### üìã –¢–µ–∫—Å—Ç–∏ –≤—ñ–¥–≥—É–∫—ñ–≤ (–¥–æ 100 –Ω–∞ –∫–æ–∂–Ω—É –∑—ñ—Ä–∫—É, max 500)")
    st.caption("–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: —Å–ø–æ—á–∞—Ç–∫—É 1‚òÖ ‚Äî —â–æ–± –ø—Ä–æ–±–ª–µ–º–∏ –±—É–ª–∏ –ø–µ—Ä—à–∏–º–∏")

    df_table = balanced_reviews(df, max_per_star=100).sort_values('rating', ascending=True)
    display_cols   = ['review_date','asin','rating','title','content','product_attributes','author','is_verified']
    available_cols = [c for c in display_cols if c in df_table.columns]

    st.dataframe(df_table[available_cols], use_container_width=True, height=450)

    star_summary = df_table['rating'].value_counts().sort_index(ascending=False)
    summary_str  = " | ".join([f"{s}‚òÖ: {c}" for s,c in star_summary.items()])
    st.caption(f"–ü–æ–∫–∞–∑–∞–Ω–æ {len(df_table)} –∑ {len(df)} –≤—ñ–¥–≥—É–∫—ñ–≤ ¬∑ {summary_str}")

    col1, col2 = st.columns(2)
    with col1:
        st.download_button("üì• –í–∏–±—ñ—Ä–∫–∞ balanced (CSV)",
            df_table[available_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_balanced_{asin_label}.csv","text/csv")
    with col2:
        st.download_button("üì• –í—Å—ñ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω—ñ (CSV)",
            df[available_cols].to_csv(index=False).encode('utf-8'),
            f"reviews_full_{asin_label}.csv","text/csv")


# ============================================
# OTHER REPORT FUNCTIONS
# ============================================

def show_overview(df_filtered, t, selected_date):
    st.markdown("### üìä Business Dashboard Overview")
    st.caption(f"Data snapshot: {selected_date}")
    col1,col2,col3,col4 = st.columns(4)
    with col1: st.metric(t["total_sku"], len(df_filtered))
    with col2: st.metric(t["total_avail"], f"{int(df_filtered['Available'].sum()):,}")
    with col3: st.metric(t["total_value"], f"${df_filtered['Stock Value'].sum():,.0f}")
    with col4: st.metric(t["velocity_30"], f"{int(df_filtered['Velocity'].sum()*30):,} units")
    st.markdown("---")
    col1,col2,col3,col4 = st.columns(4)
    btns = [
        (col1, f"#### {t['settlements_title']}", "Payouts, Net Profit, Fees", "üè¶ View Finance ‚Üí","btn_s","üè¶ Settlements (Payouts)"),
        (col2, "#### üìà Sales & Traffic","Sessions, Conversions, Buy Box","üìà View Traffic ‚Üí","btn_st","üìà Sales & Traffic"),
        (col3, "#### üõí Orders Analytics","Sales Trends, Top Products","üìä View Orders ‚Üí","btn_o","üõí Orders Analytics"),
        (col4, "#### üì¶ Returns Analytics","Return rates, Problem SKUs","üì¶ View Returns ‚Üí","btn_r","üì¶ Returns Analytics"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, use_container_width=True, type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("")
    col1,col2,col3,col4 = st.columns(4)
    btns2 = [
        (col1,"#### üí∞ Inventory Value","Money map, Pricing","üí∞ View Inventory ‚Üí","btn_f","üí∞ Inventory Value (CFO)"),
        (col2,"#### üß† AI Forecast","Sold-out predictions","üß† View AI Forecast ‚Üí","btn_a","üß† AI Forecast"),
        (col3,"#### üê¢ Inventory Health","Aging analysis","üê¢ View Health ‚Üí","btn_h","üê¢ Inventory Health (Aging)"),
        (col4,"#### ‚≠ê Amazon Reviews","Ratings, problem ASINs","‚≠ê View Reviews ‚Üí","btn_rev","‚≠ê Amazon Reviews"),
    ]
    for c,hdr,sub,btn_lbl,key,dest in btns2:
        with c:
            with st.container(border=True):
                st.markdown(hdr); st.markdown(sub)
                if st.button(btn_lbl, key=key, use_container_width=True, type="primary"):
                    st.session_state.report_choice = dest; st.rerun()
    st.markdown("---")
    st.markdown("### üìä Quick Overview: Top 15 SKU by Stock")
    if not df_filtered.empty:
        df_top = df_filtered.nlargest(15,'Available')
        fig = px.bar(df_top, x='Available', y='SKU', orientation='h',
                     text='Available', color='Available', color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'}, height=400)
        st.plotly_chart(fig, use_container_width=True)
    show_overview_insights(df_filtered)


def show_sales_traffic(t):
    df_st = load_sales_traffic()
    if df_st.empty:
        st.warning("‚ö†Ô∏è No Sales & Traffic data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("üìà Sales & Traffic Filters")
    min_date = df_st['report_date'].min().date()
    max_date = df_st['report_date'].max().date()
    date_range = st.sidebar.date_input("üìÖ Date Range:",
        value=(max(min_date, max_date-dt.timedelta(days=14)), max_date),
        min_value=min_date, max_value=max_date, key="st_date_range")
    if len(date_range)==2:
        mask = (df_st['report_date'].dt.date>=date_range[0])&(df_st['report_date'].dt.date<=date_range[1])
        df_filtered = df_st[mask]
    else:
        df_filtered = df_st
    if df_filtered.empty:
        st.warning("No data for selected period"); return
    st.markdown(f"### {t['sales_traffic_title']}")
    ts = int(df_filtered['sessions'].sum()); tpv = int(df_filtered['page_views'].sum())
    tu = int(df_filtered['units_ordered'].sum()); tr = df_filtered['ordered_product_sales'].sum()
    ac = tu/ts*100 if ts>0 else 0; ab = df_filtered['buy_box_percentage'].mean()
    c1,c2,c3,c4,c5,c6 = st.columns(6)
    c1.metric(t["st_sessions"],f"{ts:,}"); c2.metric(t["st_page_views"],f"{tpv:,}")
    c3.metric(t["st_units"],f"{tu:,}"); c4.metric(t["st_revenue"],f"${tr:,.2f}")
    c5.metric(t["st_conversion"],f"{ac:.2f}%"); c6.metric(t["st_buy_box"],f"{ab:.1f}%")
    st.markdown("---"); st.markdown("### üìà Daily Trends")
    daily = df_filtered.groupby(df_filtered['report_date'].dt.date).agg(
        {'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum'}).reset_index()
    daily.columns = ['Date','Sessions','Page Views','Units','Revenue']
    daily['Conversion %'] = (daily['Units']/daily['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### üëÅ Sessions & Page Views")
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Sessions'],name='Sessions',marker_color='#4472C4'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Page Views'],name='Page Views',mode='lines+markers',line=dict(color='#ED7D31',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Sessions'),yaxis2=dict(title='Page Views',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.markdown("#### üí∞ Revenue & Units")
        fig = go.Figure()
        fig.add_trace(go.Bar(x=daily['Date'],y=daily['Revenue'],name='Revenue $',marker_color='#70AD47'))
        fig.add_trace(go.Scatter(x=daily['Date'],y=daily['Units'],name='Units',mode='lines+markers',line=dict(color='#FFC000',width=2),yaxis='y2'))
        fig.update_layout(yaxis=dict(title='Revenue $'),yaxis2=dict(title='Units',overlaying='y',side='right'),height=380,legend=dict(orientation='h',y=1.12))
        st.plotly_chart(fig, use_container_width=True)
    fig_conv = go.Figure(go.Scatter(x=daily['Date'],y=daily['Conversion %'],mode='lines+markers+text',
        text=[f"{v:.1f}%" for v in daily['Conversion %']],textposition='top center',line=dict(color='#5B9BD5',width=3),marker=dict(size=8)))
    fig_conv.update_layout(height=300,yaxis_title='Conversion %')
    st.plotly_chart(fig_conv, use_container_width=True)
    st.markdown("---"); st.markdown("### üèÜ Top ASINs Performance")
    asin_col = 'child_asin' if 'child_asin' in df_filtered.columns else df_filtered.columns[0]
    as_ = df_filtered.groupby(asin_col).agg({'sessions':'sum','page_views':'sum','units_ordered':'sum','ordered_product_sales':'sum','buy_box_percentage':'mean'}).reset_index()
    as_.columns=['ASIN','Sessions','Page Views','Units','Revenue','Buy Box %']
    as_['Conv %'] = (as_['Units']/as_['Sessions']*100).fillna(0)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### üí∞ Top 15 by Revenue")
        fig = px.bar(as_.nlargest(15,'Revenue'),x='Revenue',y='ASIN',orientation='h',text='Revenue',color='Revenue',color_continuous_scale='Greens')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.markdown("#### üëÅ Top 15 by Sessions")
        fig = px.bar(as_.nlargest(15,'Sessions'),x='Sessions',y='ASIN',orientation='h',text='Sessions',color='Sessions',color_continuous_scale='Blues')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450)
        st.plotly_chart(fig, use_container_width=True)
    st.markdown("---"); st.markdown("### üìã Full ASIN Data")
    st.dataframe(as_.sort_values('Revenue',ascending=False).style.format({'Revenue':'${:,.2f}','Conv %':'{:.2f}%','Buy Box %':'{:.1f}%'}),use_container_width=True,height=500)
    csv = as_.to_csv(index=False).encode('utf-8')
    st.download_button("üì• Download CSV", csv, "sales_traffic.csv","text/csv")
    insights_sales_traffic(df_filtered, as_)


def show_settlements(t):
    df_settlements = load_settlements()
    if df_settlements.empty:
        st.warning("‚ö†Ô∏è No settlement data found."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("üí∞ Settlement Filters")
    currencies = ['All'] + sorted(df_settlements['Currency'].dropna().unique().tolist())
    sel_cur = st.sidebar.selectbox(t["currency_select"], currencies, index=1 if "USD" in currencies else 0)
    min_date = df_settlements['Posted Date'].min().date()
    max_date = df_settlements['Posted Date'].max().date()
    date_range = st.sidebar.date_input("üìÖ Transaction Date:",value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    df_f = df_settlements.copy()
    if sel_cur != 'All': df_f = df_f[df_f['Currency']==sel_cur]
    if len(date_range)==2:
        df_f = df_f[(df_f['Posted Date'].dt.date>=date_range[0])&(df_f['Posted Date'].dt.date<=date_range[1])]
    if df_f.empty:
        st.warning("No data for selected filters"); return
    st.markdown(f"### {t['settlements_title']}")
    net = df_f['Amount'].sum()
    gross = df_f[(df_f['Transaction Type']=='Order')&(df_f['Amount']>0)]['Amount'].sum()
    refunds = df_f[df_f['Transaction Type']=='Refund']['Amount'].sum()
    fees = df_f[(df_f['Amount']<0)&(df_f['Transaction Type']!='Refund')]['Amount'].sum()
    sym = "$" if sel_cur in ['USD','CAD','All'] else ""
    c1,c2,c3,c4 = st.columns(4)
    c1.metric(t['net_payout'],f"{sym}{net:,.2f}"); c2.metric(t['gross_sales'],f"{sym}{gross:,.2f}")
    c3.metric(t['total_refunds'],f"{sym}{refunds:,.2f}"); c4.metric(t['total_fees'],f"{sym}{fees:,.2f}")
    st.markdown("---")
    col1,col2 = st.columns([2,1])
    with col1:
        st.subheader(t['chart_payout_trend'])
        dt_ = df_f.groupby(df_f['Posted Date'].dt.date)['Amount'].sum().reset_index()
        dt_.columns=['Date','Net Amount']
        fig = go.Figure(go.Bar(x=dt_['Date'],y=dt_['Net Amount'],marker_color=dt_['Net Amount'].apply(lambda x:'green' if x>=0 else 'red')))
        fig.update_layout(height=400,yaxis_title=f"Net Amount ({sel_cur})")
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.subheader(t['chart_fee_breakdown'])
        df_costs = df_f[df_f['Amount']<0]
        if not df_costs.empty:
            cb = df_costs.groupby('Transaction Type')['Amount'].sum().abs().reset_index()
            fig = px.pie(cb,values='Amount',names='Transaction Type',hole=0.4)
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        else: st.info("No costs in selected period")
    disp = ['Posted Date','Transaction Type','Order ID','Amount','Currency','Description']
    st.dataframe(df_f[[c for c in disp if c in df_f.columns]].sort_values('Posted Date',ascending=False).head(100),use_container_width=True)
    insights_settlements(df_f)


def show_returns():
    df_ret_raw, df_orders = load_returns()
    if df_ret_raw.empty:
        st.warning("‚ö†Ô∏è No returns data."); return
    df_r = df_ret_raw.copy()
    df_r['Return Date'] = pd.to_datetime(df_r['Return Date'], errors='coerce')
    if 'Price' not in df_r.columns and not df_orders.empty:
        try:
            for col in ['Item Price','item-price','item_price','price','Price']:
                if col in df_orders.columns:
                    df_orders[col] = pd.to_numeric(df_orders[col],errors='coerce')
                    df_r['Price'] = df_r['SKU'].map(df_orders.groupby('SKU')[col].mean()).fillna(0)
                    break
        except: df_r['Price'] = 0
    elif 'Price' not in df_r.columns: df_r['Price'] = 0
    df_r['Price']        = pd.to_numeric(df_r['Price'],errors='coerce').fillna(0)
    df_r['Quantity']     = pd.to_numeric(df_r['Quantity'],errors='coerce').fillna(1)
    df_r['Return Value'] = df_r['Price'] * df_r['Quantity']
    st.sidebar.markdown("---"); st.sidebar.subheader("üì¶ Returns Filters")
    min_date = df_r['Return Date'].min().date(); max_date = df_r['Return Date'].max().date()
    date_range = st.sidebar.date_input("üìÖ Return Date:",value=(max_date-dt.timedelta(days=30),max_date),min_value=min_date,max_value=max_date)
    sel_store = 'All'
    if 'Store Name' in df_r.columns:
        stores = ['All'] + sorted(df_r['Store Name'].dropna().unique().tolist())
        sel_store = st.sidebar.selectbox("üè™ Store:", stores)
    df_f = df_r[(df_r['Return Date'].dt.date>=date_range[0])&(df_r['Return Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_r
    if sel_store != 'All': df_f = df_f[df_f['Store Name']==sel_store]
    st.markdown("### üì¶ Returns Overview")
    rr = 0
    try:
        if not df_orders.empty:
            for col in ['Order ID','order-id','order_id','OrderID']:
                if col in df_orders.columns:
                    rr = df_f['Order ID'].nunique()/df_orders[col].nunique()*100 if df_orders[col].nunique()>0 else 0
                    break
    except: pass
    c1,c2,c3,c4,c5 = st.columns(5)
    c1.metric("üì¶ Total Returns",f"{len(df_f):,}"); c2.metric("üì¶ Unique SKUs",df_f['SKU'].nunique())
    c3.metric("üìä Return Rate",f"{rr:.1f}%"); c4.metric("üí∞ Return Value",f"${df_f['Return Value'].sum():,.2f}")
    c5.metric("üíµ Avg Return",f"${df_f['Return Value'].mean():.2f}")
    st.markdown("---")
    col1,col2,col3 = st.columns(3)
    with col1:
        st.markdown("#### üíµ Return Value by SKU (Top 10)")
        tv = df_f.groupby('SKU')['Return Value'].sum().nlargest(10).reset_index()
        fig = px.bar(tv,x='Return Value',y='SKU',orientation='h',text='Return Value',color='Return Value',color_continuous_scale='Reds')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=350); fig.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.markdown("#### üìä Daily Return Value")
        dv = df_f.groupby(df_f['Return Date'].dt.date)['Return Value'].sum().reset_index(); dv.columns=['Date','Value']
        fig = px.area(dv,x='Date',y='Value',line_shape='spline',color_discrete_sequence=['#FF6B6B'])
        fig.update_layout(height=350); st.plotly_chart(fig, use_container_width=True)
    with col3:
        if 'Reason' in df_f.columns:
            st.markdown("#### üí∏ Return Value by Reason")
            rv = df_f.groupby('Reason')['Return Value'].sum().nlargest(8).reset_index()
            fig = px.pie(rv,values='Return Value',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=350); st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### üèÜ Top 15 Returned SKUs")
        ts = df_f['SKU'].value_counts().head(15).reset_index(); ts.columns=['SKU','Returns']
        fig = px.bar(ts,x='Returns',y='SKU',orientation='h',color='Returns',color_continuous_scale='Oranges',text='Returns')
        fig.update_layout(yaxis={'categoryorder':'total ascending'},height=450); st.plotly_chart(fig, use_container_width=True)
    with col2:
        if 'Reason' in df_f.columns:
            st.markdown("#### üìä Return Reasons")
            rs = df_f['Reason'].value_counts().head(10).reset_index(); rs.columns=['Reason','Count']
            fig = px.pie(rs,values='Count',names='Reason',hole=0.4,color_discrete_sequence=px.colors.sequential.RdBu)
            fig.update_layout(height=450); st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")
    dc = ['Return Date','SKU','Product Name','Quantity','Price','Return Value','Reason','Status']
    st.dataframe(df_f[[c for c in dc if c in df_f.columns]].sort_values('Return Date',ascending=False).head(100).style.format({'Price':'${:.2f}','Return Value':'${:.2f}'}),use_container_width=True)
    st.download_button("üì• Download Returns CSV",df_f.to_csv(index=False).encode('utf-8'),"returns.csv","text/csv")
    insights_returns(df_f, rr)


def show_inventory_finance(df_filtered, t):
    tv = df_filtered['Stock Value'].sum(); tu = df_filtered['Available'].sum()
    ap = df_filtered[df_filtered['Price']>0]['Price'].mean()
    c1,c2,c3 = st.columns(3)
    c1.metric("üí∞ Total Inventory Value",f"${tv:,.2f}")
    c2.metric(t["avg_price"],f"${ap:,.2f}" if not pd.isna(ap) else "$0")
    c3.metric("üíµ Avg Value per Unit",f"${tv/tu:.2f}" if tu>0 else "$0")
    st.markdown("---"); st.subheader(t["chart_value_treemap"])
    dm = df_filtered[df_filtered['Stock Value']>0]
    if not dm.empty:
        fig = px.treemap(dm,path=['Store Name','SKU'],values='Stock Value',color='Stock Value',color_continuous_scale='RdYlGn_r')
        st.plotly_chart(fig, use_container_width=True)
    st.subheader(t["top_money_sku"])
    dt_ = df_filtered[['SKU','Product Name','Available','Price','Stock Value']].sort_values('Stock Value',ascending=False).head(10)
    st.dataframe(dt_.style.format({'Price':"${:.2f}",'Stock Value':"${:,.2f}"}),use_container_width=True)
    insights_inventory(df_filtered)


def show_aging(df_filtered, t):
    if df_filtered.empty: st.warning("No data"); return
    age_cols = ['Upto 90 Days','91 to 180 Days','181 to 270 Days','271 to 365 Days','More than 365 Days']
    valid    = [c for c in age_cols if c in df_filtered.columns]
    if not valid: st.warning("Aging data not available."); return
    da = df_filtered[valid].copy()
    for c in valid: da[c] = pd.to_numeric(da[c],errors='coerce').fillna(0)
    if da.sum().sum()==0: st.info("All inventory is fresh"); return
    as_ = da.sum().reset_index(); as_.columns=['Age Group','Units']; as_ = as_[as_['Units']>0]
    col1,col2 = st.columns(2)
    with col1:
        st.subheader(t["chart_age"])
        fig = px.pie(as_,values='Units',names='Age Group',hole=0.4); fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    with col2:
        st.subheader(t["chart_velocity"])
        if all(c in df_filtered.columns for c in ['Available','Velocity','Stock Value']):
            ds = df_filtered[(df_filtered['Available']>0)&(df_filtered['Velocity']>=0)&(df_filtered['Stock Value']>0)].copy()
            if not ds.empty:
                fig = px.scatter(ds,x='Available',y='Velocity',size='Stock Value',color='Store Name' if 'Store Name' in ds.columns else None,hover_name='SKU',log_x=True)
                fig.update_layout(height=400); st.plotly_chart(fig, use_container_width=True)


def show_ai_forecast(df, t):
    st.markdown("### Select SKU for Forecast")
    skus = sorted(df['SKU'].unique())
    if not skus: st.info("No SKU available"); return
    col1,col2 = st.columns([2,1])
    target_sku    = col1.selectbox(t["ai_select"],skus)
    forecast_days = col2.slider(t["ai_days"],7,90,30)
    sd = df[df['SKU']==target_sku].copy().sort_values('created_at')
    sd['date_ordinal'] = sd['created_at'].map(dt.datetime.toordinal)
    if len(sd)>=3:
        model = LinearRegression().fit(sd[['date_ordinal']], sd['Available'])
        last  = sd['created_at'].max()
        fd    = [last+dt.timedelta(days=x) for x in range(1,forecast_days+1)]
        fo    = np.array([d.toordinal() for d in fd]).reshape(-1,1)
        preds = [max(0,int(p)) for p in model.predict(fo)]
        df_fc = pd.DataFrame({'date':fd,'Predicted':preds})
        so    = df_fc[df_fc['Predicted']==0]
        if not so.empty: st.error(f"{t['ai_result_date']} **{so.iloc[0]['date'].date()}**")
        else:             st.success(t['ai_ok'])
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=sd['created_at'],y=sd['Available'],name='Historical'))
        fig.add_trace(go.Scatter(x=df_fc['date'],y=df_fc['Predicted'],name='Forecast',line=dict(dash='dash',color='red')))
        st.plotly_chart(fig, use_container_width=True)
    else: st.warning(t["ai_error"])


def show_data_table(df_filtered, t, selected_date):
    st.markdown("### üìä FBA Inventory Dataset")
    st.download_button("üì• Download CSV",df_filtered.to_csv(index=False).encode('utf-8'),"fba_inventory.csv","text/csv")
    st.dataframe(df_filtered, use_container_width=True, height=600)


def show_orders():
    df_orders = load_orders()
    if df_orders.empty: st.warning("‚ö†Ô∏è No orders data."); return
    st.sidebar.markdown("---"); st.sidebar.subheader("üõí Orders Filters")
    min_date = df_orders['Order Date'].min().date(); max_date = df_orders['Order Date'].max().date()
    date_range = st.sidebar.date_input("üìÖ Date Range:",value=(max_date-dt.timedelta(days=7),max_date),min_value=min_date,max_value=max_date)
    df_f = df_orders[(df_orders['Order Date'].dt.date>=date_range[0])&(df_orders['Order Date'].dt.date<=date_range[1])] if len(date_range)==2 else df_orders
    c1,c2,c3 = st.columns(3)
    c1.metric("üì¶ Orders",df_f['Order ID'].nunique()); c2.metric("üí∞ Revenue",f"${df_f['Total Price'].sum():,.2f}"); c3.metric("üì¶ Items",int(df_f['Quantity'].sum()))
    st.markdown("#### üìà Daily Revenue")
    daily = df_f.groupby(df_f['Order Date'].dt.date)['Total Price'].sum().reset_index()
    fig = px.bar(daily,x='Order Date',y='Total Price',title="Daily Revenue")
    st.plotly_chart(fig, use_container_width=True)
    col1,col2 = st.columns(2)
    with col1:
        st.markdown("#### üèÜ Top 10 SKU by Revenue")
        ts = df_f.groupby('SKU')['Total Price'].sum().nlargest(10).reset_index()
        fig2 = px.bar(ts,x='Total Price',y='SKU',orientation='h'); fig2.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig2, use_container_width=True)
    with col2:
        if 'Order Status' in df_f.columns:
            st.markdown("#### üìä Order Status")
            sc = df_f['Order Status'].value_counts().reset_index(); sc.columns=['Status','Count']
            fig3 = px.pie(sc,values='Count',names='Status',hole=0.4); st.plotly_chart(fig3, use_container_width=True)
    insights_orders(df_f)


# ============================================
# MAIN
# ============================================

if 'report_choice' not in st.session_state:
    st.session_state.report_choice = "üè† Overview"

lang_option = st.sidebar.selectbox("üåç Language", ["UA üá∫üá¶","EN üá∫üá∏","RU üåç"], index=0)
lang = "UA" if "UA" in lang_option else "EN" if "EN" in lang_option else "RU"
t    = translations[lang]

if st.sidebar.button(t["update_btn"], use_container_width=True):
    st.cache_data.clear(); st.rerun()

df = load_data()

if not df.empty:
    for col in ['Available','Price','Velocity','Stock Value']:
        if col not in df.columns: df[col] = 0
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    df['Stock Value'] = df['Available'] * df['Price']
    df['created_at']  = pd.to_datetime(df['created_at'])
    df['date']        = df['created_at'].dt.date
    st.sidebar.header(t["sidebar_title"])
    dates         = sorted(df['date'].unique(), reverse=True)
    selected_date = st.sidebar.selectbox(t["date_label"], dates) if dates else None
    stores        = [t["all_stores"]] + list(df['Store Name'].unique()) if 'Store Name' in df.columns else [t["all_stores"]]
    selected_store = st.sidebar.selectbox(t["store_label"], stores)
    df_filtered    = df[df['date']==selected_date] if selected_date else df
    if selected_store != t["all_stores"]:
        df_filtered = df_filtered[df_filtered['Store Name']==selected_store]
else:
    df_filtered = pd.DataFrame(); selected_date = None

st.sidebar.markdown("---")
st.sidebar.header("üìä Reports")
report_options = [
    "üè† Overview","üìà Sales & Traffic","üè¶ Settlements (Payouts)",
    "üí∞ Inventory Value (CFO)","üõí Orders Analytics","üì¶ Returns Analytics",
    "‚≠ê Amazon Reviews","üê¢ Inventory Health (Aging)","üß† AI Forecast","üìã FBA Inventory Table"
]
current_index = report_options.index(st.session_state.report_choice) if st.session_state.report_choice in report_options else 0
report_choice = st.sidebar.radio("Select Report:", report_options, index=current_index)
st.session_state.report_choice = report_choice

if   report_choice == "üè† Overview":                show_overview(df_filtered, t, selected_date)
elif report_choice == "üìà Sales & Traffic":          show_sales_traffic(t)
elif report_choice == "üè¶ Settlements (Payouts)":   show_settlements(t)
elif report_choice == "üí∞ Inventory Value (CFO)":   show_inventory_finance(df_filtered, t)
elif report_choice == "üõí Orders Analytics":         show_orders()
elif report_choice == "üì¶ Returns Analytics":        show_returns()
elif report_choice == "‚≠ê Amazon Reviews":           show_reviews(t)
elif report_choice == "üê¢ Inventory Health (Aging)":show_aging(df_filtered, t)
elif report_choice == "üß† AI Forecast":              show_ai_forecast(df, t)
elif report_choice == "üìã FBA Inventory Table":      show_data_table(df_filtered, t, selected_date)

st.sidebar.markdown("---")
st.sidebar.caption("üì¶ Amazon FBA BI System v3.4")
